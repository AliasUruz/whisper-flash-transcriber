# Whisper Flash Transcriber

Whisper Flash Transcriber is a high-performance, hotkey-driven audio transcription assistant that runs entirely on your machine. It is ideal for dictating text, transcribing meetings, or turning any audio into polished text while keeping every recording private.

## Key Features

- **Hotkey Recording:** Start and stop audio capture instantly with a customizable global shortcut.
- **Recording Modes:** Toggle mode (press once to start, press again to stop) and Hold mode (record only while the key is held).
- **Local Transcription:** Harness the Whisper family of models locally for reliable, private speech-to-text conversion.
- **Optional AI Post-processing:** Connect services such as Gemini or OpenRouter to automatically polish punctuation and grammar.
- **Agent Mode:** Run more advanced AI-driven commands over captured audio segments.
- **Automatic Paste:** Optionally paste the final transcription directly into the currently focused application.

## Installation

### Prerequisites

- Python 3.9 or newer.
- Git (to clone the repository).

### Setup Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/<your-account>/whisper-flash-transcriber.git
   cd whisper-flash-transcriber
   ```

2. **Create and activate a virtual environment:**
   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # Linux / macOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install the required dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
   The pinned dependencies include the CPU build of PyTorch (2.5.1) so that Windows users can install the project without
   touching custom package indexes. If you plan to leverage a GPU, install the base requirements first and then follow the
   guidance in the section below to swap in the CUDA-enabled wheel that matches your driver.

### Optional: GPU Acceleration

For significantly faster transcription you can leverage an NVIDIA GPU. Install PyTorch with CUDA support following the official instructions once the base requirements are installed:

1. Visit the [PyTorch installation guide](https://pytorch.org/get-started/locally/).
2. Select the desired PyTorch build, operating system, package manager, Python version, and CUDA version.
3. Run the installation command generated by the configurator. It looks similar to:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```
   Always use the command suggested on the official PyTorch website for your environment.

### Optional: Advanced GPU and quantization extras

Install the optional requirements only when you need GPU-centric optimizations such as quantized models:

```bash
pip install -r requirements-optional.txt
```

This set contains packages such as `bitsandbytes`. Upstream only ships prebuilt wheels for Linux (including WSL) and conda-based setups, so Windows users running native `pip` should skip this step or use WSL/conda when GPU quantization is required.

## Usage

### First Run

Launch the application for the first time with:
```bash
python src/main.py
```
During the initial startup the application will create the persistent profile under
`~/.cache/whisper_flash_transcriber/` (or the directory pointed to by the
`WHISPER_FLASH_PROFILE_DIR` environment variable). The preflight stage ensures that
`config.json`, `secrets.json`, and `hotkey_config.json` exist inside that profile
folder before continuing, so the bootstrap completes successfully even when the
installation directory is read-only.

### Configuration

- The application icon appears in the system tray.
- Right-click the icon and choose **Settings**.
- From the settings window you can:
  - Configure the recording hotkey.
  - Select the ASR model. If a model is missing, the application offers to download it.
  - Fine-tune where the application stores heavyweight assets:
    - Set a base storage root for cached data.
    - Override the dedicated models directory and its derived ASR cache path.
    - Choose a separate recordings folder for WAV artifacts.
  - Configure AI services, audio feedback sounds, and additional quality-of-life options.

### Recording and Transcribing

- Press the configured hotkey to begin recording.
- Press again (or release, depending on the chosen mode) to stop.
- The application transcribes the captured audio and, if enabled, copies the final result to the clipboard and pastes it into the active window.

### Windows permissions and global hotkeys

The application registers global shortcuts using the [`keyboard`](https://github.com/boppreh/keyboard) library. Key suppression is intentionally disabled so that hotkeys work without elevated privileges on Windows. If you customize the code to block the underlying key events system-wide, make sure to run the application as an administrator to satisfy the library requirements.

## Architecture Overview

- **`main.py`:** Application entry point that initializes `AppCore` and the user interface.
- **`core.py`:** Coordinates modules and maintains global application state.
- **`ui_manager.py`:** Manages the GUI, settings window, and system tray icon.
- **`audio_handler.py`:** Captures audio from the microphone and routes it to storage.
- **`transcription_handler.py`:** Loads Whisper models and performs speech recognition.
- **`config_manager.py`:** Loads and persists user configuration.

For detailed developer notes and diagrams, review the files under the `docs/` directory.
