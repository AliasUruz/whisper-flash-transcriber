# Whisper Flash Transcriber

Whisper Flash Transcriber is a high-performance, hotkey-driven audio transcription assistant that runs entirely on your machine. It is ideal for dictating text, transcribing meetings, or turning any audio into polished text while keeping every recording private.

## Key Features

- **Hotkey Recording:** Start and stop audio capture instantly with a customizable global shortcut.
- **Recording Modes:** Toggle mode (press once to start, press again to stop) and Hold mode (record only while the key is held).
- **Local Transcription:** Harness the Whisper family of models locally for reliable, private speech-to-text conversion.
- **Optional AI Post-processing:** Connect services such as Gemini or OpenRouter to automatically polish punctuation and grammar.
- **Agent Mode:** Run more advanced AI-driven commands over captured audio segments.
- **Automatic Paste:** Optionally paste the final transcription directly into the currently focused application.

## Installation

### Prerequisites

- Python 3.9 or newer.
- Git (to clone the repository).

### Setup Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/<your-account>/whisper-flash-transcriber.git
   cd whisper-flash-transcriber
   ```

2. **Create and activate a virtual environment:**
   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # Linux / macOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install the required dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
   The pinned dependencies include the CPU build of PyTorch (2.5.1) so that Windows users can install the project without
   touching custom package indexes. If you plan to leverage a GPU, install the base requirements first and then follow the
   guidance in the section below to swap in the CUDA-enabled wheel that matches your driver.

### Optional: GPU Acceleration

For significantly faster transcription you can leverage an NVIDIA GPU. Install PyTorch with CUDA support following the official instructions once the base requirements are installed:

1. Visit the [PyTorch installation guide](https://pytorch.org/get-started/locally/).
2. Select the desired PyTorch build, operating system, package manager, Python version, and CUDA version.
3. Run the installation command generated by the configurator. It looks similar to:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```
   Always use the command suggested on the official PyTorch website for your environment.

### Optional: Advanced GPU and quantization extras

Install the optional requirements only when you need GPU-centric optimizations such as quantized models:

```bash
pip install -r requirements-optional.txt
```

This set contains packages such as `bitsandbytes`. Upstream only ships prebuilt wheels for Linux (including WSL) and conda-based setups, so Windows users running native `pip` should skip this step or use WSL/conda when GPU quantization is required.

## Usage

### First Run

Launch the application for the first time with:
```bash
python src/main.py
```
During the initial startup the application will create the persistent profile under
`~/.cache/whisper_flash_transcriber/` (or the directory pointed to by the
`WHISPER_FLASH_PROFILE_DIR` environment variable). The preflight stage ensures that
`config.json`, `secrets.json`, and `hotkey_config.json` exist inside that profile
folder before continuing, so the bootstrap completes successfully even when the
installation directory is read-only.

## First launch experience

When the profile is brand-new the application presents a guided first-run wizard
before the tray UI is initialized. The wizard is built with `customtkinter` and
walks through the following stages:

1. **Directories:** select the base storage root, the dedicated models cache,
   and the WAV recordings directory. Each field can target a different drive so
   large downloads stay off the system disk.
2. **ASR bootstrap:** choose the curated backend and Whisper model that should
   be loaded after startup. The wizard keeps the backend aligned with the model
   catalog to avoid incompatible combinations.
3. **Capture preferences:** toggle voice activity detection as well as the
   automatic paste behaviour for both standard transcriptions and Agent mode.
4. **Optional installations:** flag curated models and extra Python packages
   for the bootstrapper. Selected models are downloaded automatically once the
   main window is ready, while optional packages are logged so they can be
   installed via `pip`.
5. **Summary and snapshot:** a checklist summarises every decision and offers
   an optional export that writes a Markdown report to `plans/`.

The configuration choices are persisted through `ConfigManager` before the
`AppCore` instance is created, guaranteeing that the main UI launches with the
requested storage locations and backend already applied.

### Configuration

- The application icon appears in the system tray.
- Right-click the icon and choose **Settings**.
- From the settings window you can:
  - Configure the recording hotkey.
  - Select the ASR model. If a model is missing, the application offers to download it.
  - Fine-tune where the application stores heavyweight assets:
    - Set a base storage root for cached data.
    - Override the dedicated models directory and its derived ASR cache path.
    - Choose a separate recordings folder for WAV artifacts.
    - Point the embedded dependency installer to a custom Python packages directory.
    - Choose explicit locations for the Silero VAD model and the shared Hugging Face cache.
  - Configure AI services, audio feedback sounds, and additional quality-of-life options.

### Custom installation directories

The application allows you to relocate heavyweight assets so that ephemeral or slow system drives do not become bottlenecks. The
following directories can be configured either directly in `config.json` or through the first-run wizard and the Settings UI:

- **`python_packages_dir`** — Target passed to `pip install --target` when optional packages (faster-whisper, ctranslate2,
  onnxruntime, etc.) are installed through the dependency remediation workflow. When you place this directory outside the active
virtual environment, ensure that `PYTHONPATH` includes the path before launching the application. The bootstrap logic adds the
directory to `sys.path`, but external scripts or shells may require explicit exports.
- **`vad_models_dir`** — Dedicated folder for the Silero VAD model. If empty, the packaged copy is copied into the directory on
  first use. Keep this path on a fast local drive to avoid I/O stalls during VAD activation.
- **`hf_cache_dir`** — Shared Hugging Face cache that backs `snapshot_download` calls and any Transformers pipelines. The
  bootstrap sequence creates the directory and sets `HF_HOME`/`HUGGINGFACE_HUB_CACHE` accordingly.

Because all these directories default to the storage root, you can move the entire cache tree by changing `storage_root_dir` or
override each path individually for more granular layouts.

### Recording and Transcribing

- Press the configured hotkey to begin recording.
- Press again (or release, depending on the chosen mode) to stop.
- The application transcribes the captured audio and, if enabled, copies the final result to the clipboard and pastes it into the active window.

### Windows permissions and global hotkeys

The application registers global shortcuts using the [`keyboard`](https://github.com/boppreh/keyboard) library. Key suppression is intentionally disabled so that hotkeys work without elevated privileges on Windows. If you customize the code to block the underlying key events system-wide, make sure to run the application as an administrator to satisfy the library requirements.

## Architecture Overview

- **`main.py`:** Application entry point that initializes `AppCore` and the user interface.
- **`core.py`:** Coordinates modules and maintains global application state.
- **`ui_manager.py`:** Manages the GUI, settings window, and system tray icon.
- **`audio_handler.py`:** Captures audio from the microphone and routes it to storage.
- **`transcription_handler.py`:** Loads Whisper models and performs speech recognition.
- **`config_manager.py`:** Loads and persists user configuration.

For detailed developer notes and diagrams, review the files under the `docs/` directory.
