# Whisper Flash Transcriber

Whisper Flash Transcriber is a high-performance, hotkey-driven audio transcription assistant that runs entirely on your machine. It is ideal for dictating text, transcribing meetings, or turning any audio into polished text while keeping every recording private.

## Key Features

- **Hotkey Recording:** Start and stop audio capture instantly with a customizable global shortcut.
- **Recording Modes:** Toggle mode (press once to start, press again to stop) and Hold mode (record only while the key is held).
- **Local Transcription:** Harness the Whisper family of models locally for reliable, private speech-to-text conversion.
- **Optional AI Post-processing:** Connect services such as Gemini or OpenRouter to automatically polish punctuation and grammar.
- **Agent Mode:** Run more advanced AI-driven commands over captured audio segments.
- **Automatic Paste:** Optionally paste the final transcription directly into the currently focused application.
- **Resilient Model Management:** Automatic resume/cancel support, disk-space validation with safety margin, and metadata tracking make model installs safer and fully observable.

## Installation

### Prerequisites

- Python 3.9 or newer.
- Git (to clone the repository).

### Setup Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/<your-account>/whisper-flash-transcriber.git
   cd whisper-flash-transcriber
   ```

2. **Create and activate a virtual environment:**
   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # Linux / macOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install the required dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
   The pinned dependencies include the CPU build of PyTorch (2.5.1) so that Windows users can install the project without
   touching custom package indexes. If you plan to leverage a GPU, install the base requirements first and then follow the
   guidance in the section below to swap in the CUDA-enabled wheel that matches your driver.

### Optional: GPU Acceleration

For significantly faster transcription you can leverage an NVIDIA GPU. Install PyTorch with CUDA support following the official instructions once the base requirements are installed:

1. Visit the [PyTorch installation guide](https://pytorch.org/get-started/locally/).
2. Select the desired PyTorch build, operating system, package manager, Python version, and CUDA version.
3. Run the installation command generated by the configurator. It looks similar to:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```
   Always use the command suggested on the official PyTorch website for your environment.

### Optional: Advanced GPU and quantization extras

Install the optional requirements only when you need GPU-centric optimizations such as quantized models:

```bash
pip install -r requirements-optional.txt
```

This set contains packages such as `bitsandbytes`. Upstream only ships prebuilt wheels for Linux (including WSL) and conda-based setups, so Windows users running native `pip` should skip this step or use WSL/conda when GPU quantization is required.

## Usage

### First Run

Launch the application for the first time with:
```bash
python src/main.py
```
During the initial startup the application will create the persistent profile under
`~/.cache/whisper_flash_transcriber/` (or the directory pointed to by the
`WHISPER_FLASH_PROFILE_DIR` environment variable). The preflight stage ensures that
`config.json`, `secrets.json`, and `hotkey_config.json` exist inside that profile
folder before continuing, so the bootstrap completes successfully even when the
installation directory is read-only.

### Configuration

- The application icon appears in the system tray.
- Right-click the icon and choose **Settings**.
- From the settings window you can:
  - Configure the recording hotkey.
  - Select the ASR model. If a model is missing, the application offers to download it.
  - Fine-tune where the application stores heavyweight assets:
    - Set a base storage root for cached data.
    - Override the dedicated models directory and its derived ASR cache path.
    - Choose a separate recordings folder for WAV artifacts.
    - Trigger safe migration of existing caches/recordings when moving the storage root without losing files.
  - Configure AI services, audio feedback sounds, and additional quality-of-life options.
  - Calibrate VAD behaviour with pre/post speech padding, minimum durations, and silence thresholds.

### Recording and Transcribing

- Press the configured hotkey to begin recording.
- Press again (or release, depending on the chosen mode) to stop.
- The application transcribes the captured audio and, if enabled, copies the final result to the clipboard and pastes it into the active window.

### Model download lifecycle

When a model install is required, the core service performs a deterministic sequence:

1. Persist `status=in_progress` with the selected model/backend so the UI and logs remain aligned.
2. Estimate download size via Hugging Face, add a 10% (minimum 256 MiB) safety margin, and abort with a descriptive error if free space is insufficient.
3. Clean up any stale directories, resume partial transfers when possible, and expose a cancellable progress bar.
4. Validate the installation (including essential files and metadata) before returning the application to `IDLE`.
5. Persist the resulting status (`success`, `skipped`, `cancelled`, or `error`) alongside the resolved installation path for future audits.

These safeguards ensure that repeated launches avoid redundant downloads and that any failure is actionable without inspecting the filesystem manually.

### Storage relocation workflow

Changing the storage root inside **Settings** immediately evaluates whether the previous base directory differs from the new target. When the user has not overridden the model cache or recordings directories, the configuration manager automatically moves the existing folders, skipping migration if the destination already hosts data. Every move operation is logged with structured metadata so audits can confirm where heavy assets live after the change.

### Advanced VAD controls

Voice Activity Detection now exposes pre- and post-speech padding in milliseconds. These values let you preserve audio context before the first spoken frame and keep trailing silence to avoid clipping. Invalid inputs automatically fall back to safe defaults, and the pipeline stays in sync with the stored configuration even when values are edited manually in `config.json`.

### Windows permissions and global hotkeys

The application registers global shortcuts using the [`keyboard`](https://github.com/boppreh/keyboard) library. Key suppression is intentionally disabled so that hotkeys work without elevated privileges on Windows. If you customize the code to block the underlying key events system-wide, make sure to run the application as an administrator to satisfy the library requirements.

## Testing and validation

Automated checks:

- `python -m compileall src` — validates that all Python modules compile.
- `pytest` — executes the available test suite.

Manual verification (recommended after storage or model changes):

1. **Model download resilience**
   - Delete or rename the cached model directory for a small model.
   - Launch the app and accept the download prompt.
   - Confirm that the download can be cancelled mid-transfer and that the settings window reflects the `cancelled` status before retrying.
   - Retry the download to ensure the installation completes and `status=success` is recorded.
2. **Storage relocation**
   - In Settings, change the storage root to an empty directory.
   - Ensure that both the model cache and recordings directories move automatically when no overrides are present.
   - Repeat the process with overrides enabled to confirm that migrations are skipped and logs report the decision.
3. **Dependency audit**
   - Run `pip list --outdated` inside the virtual environment to review available updates.
   - For each candidate library, cross-check release notes before upgrading and rerun `pytest` to verify compatibility.

Document any deviations or failures inside the `plans/` folder so future operators can trace remediation steps.

## Architecture Overview

- **`main.py`:** Application entry point that initializes `AppCore` and the user interface.
- **`core.py`:** Coordinates modules and maintains global application state.
- **`ui_manager.py`:** Manages the GUI, settings window, and system tray icon.
- **`audio_handler.py`:** Captures audio from the microphone and routes it to storage.
- **`transcription_handler.py`:** Loads Whisper models and performs speech recognition.
- **`config_manager.py`:** Loads and persists user configuration.

For detailed developer notes and diagrams, review the files under the `docs/` directory.
